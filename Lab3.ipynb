{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Загрузка бизнес-процесса и преобразование его в сеть Петри",
   "id": "919e92e82b94592e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from pm4py import read_bpmn, convert_to_petri_net, write_xes, convert_to_dataframe, read_xes, discover_petri_net_alpha_plus\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "from pm4py.visualization.transition_system import visualizer as ts_visualizer\n",
    "from pm4py.visualization.process_tree import visualizer as pt_visualizer\n",
    "from pm4py.visualization.heuristics_net import visualizer as hn_visualizer\n",
    "from pm4py.objects.conversion.process_tree import converter as pt_converter\n",
    "from pm4py.algo.simulation.playout.petri_net import algorithm as simulator\n",
    "from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner\n",
    "from pm4py.algo.evaluation.replay_fitness import algorithm as replay_fitness\n",
    "from pm4py.algo.conformance.tokenreplay import algorithm as conformance_diagnostics_token_based_replay\n",
    "from pm4py.algo.analysis.woflan import algorithm as woflan\n",
    "from pm4py.objects.petri_net.utils import reachability_graph\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "bpmn_graph = read_bpmn('lab_Vinogradov.bpmn')\n",
    "\n",
    "net, initial_marking, final_marking = convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "print(\"Process Installed\")\n",
    "print(f\"Количество переходов: {len(net.transitions)}\")\n",
    "print(f\"Количество позиций: {len(net.places)}\")\n",
    "print(f\"Начальная маркировка: {initial_marking}\")\n",
    "print(f\"Конечная маркировка: {final_marking}\")\n",
    "\n",
    "gviz = pn_visualizer.apply(net, initial_marking, final_marking)\n",
    "pn_visualizer.view(gviz)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "С ноутбука",
   "id": "d84d993f3a9a2164"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bpmn_graph = read_bpmn('lab_Vinogradov.bpmn')\n",
    "net,im,fm = convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "gviz = pn_visualizer.apply(\n",
    "    net,\n",
    "    im,\n",
    "    fm,\n",
    "    parameters={\"debug\": True, \"set_rankdir\": \"LR\"} # set_rankdir for horizontal layout\n",
    ")\n",
    "\n",
    "# Render and view the graph\n",
    "pn_visualizer.view(gviz)\n"
   ],
   "id": "d75e57ed9edb231b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Построение графа достижимости маркировок",
   "id": "aa726e203646d41d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ts = reachability_graph.construct_reachability_graph(net, initial_marking)\n",
    "\n",
    "gviz_ts = ts_visualizer.apply(ts, parameters={ts_visualizer.Variants.VIEW_BASED.value.Parameters.FORMAT: \"png\"})\n",
    "ts_visualizer.view(gviz_ts)\n",
    "\n",
    "print(f\"Количество состояний (маркировок): {len(ts.states)}\")\n",
    "print(f\"Количество переходов между состояниями: {len(ts.transitions)}\")"
   ],
   "id": "47093e91c810401b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "net, initial_marking, final_marking = convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "from pm4py.objects.petri_net.utils import reachability_graph\n",
    "\n",
    "#конструируем граф достижимости встроенными средствами\n",
    "ts=reachability_graph.construct_reachability_graph(net,initial_marking)\n",
    "\n",
    "from pm4py.visualization.transition_system import visualizer as ts_visualizer\n",
    "\n",
    "gviz=ts_visualizer.apply(ts,parameters={ts_visualizer.Variants.VIEW_BASED.value.Parameters.FORMAT:\"png\"})\n",
    "ts_visualizer.view(gviz)\n",
    "\n"
   ],
   "id": "391d3cf0e0584c6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#построения графа покрытия маркировок и графа достижимости маркировок срдествами woflan\n",
    "\n",
    "from pm4py.algo.analysis.woflan.graphs.minimal_coverability_graph import minimal_coverability_graph\n",
    "from pm4py.algo.analysis.woflan.graphs.reachability_graph import reachability_graph\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#граф покрытия\n",
    "cg=minimal_coverability_graph.apply(net, initial_marking, final_marking)\n",
    "\n",
    "#граф достижимости\n",
    "rg=reachability_graph.apply(net, initial_marking, final_marking)\n"
   ],
   "id": "76862d8e56136337",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Это максимум, которого я смог добиться, чтобы качество было максимально не шакальным",
   "id": "74ef30c2216d5b0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.drawing.nx_agraph import graphviz_layout, to_agraph\n",
    "import pygraphviz as pgv  # можно установить без использования напрямую\n",
    "\n",
    "def vizualizeGraph_graphviz(network):\n",
    "    \"\"\"Использование Graphviz layout через NetworkX\"\"\"\n",
    "    is_bounded = True\n",
    "\n",
    "    # Проверка на неограниченность\n",
    "    for node, attributes in network.nodes(data=True):\n",
    "        marking = attributes.get('marking', [])\n",
    "        for pos in marking:\n",
    "            if pos == float('inf'):\n",
    "                is_bounded = False\n",
    "\n",
    "    # Создаем граф AGraph для использования Graphviz\n",
    "    A = to_agraph(network)\n",
    "\n",
    "    # Настраиваем атрибуты как в исходном коде\n",
    "    A.graph_attr['rankdir'] = 'LR'\n",
    "    A.node_attr['shape'] = 'ellipse'\n",
    "\n",
    "    # Устанавливаем метки узлов\n",
    "    for node in network.nodes():\n",
    "        marking = network.nodes[node].get('marking', '')\n",
    "        n = A.get_node(node)\n",
    "        n.attr['label'] = str(marking)\n",
    "\n",
    "    # Устанавливаем метки ребер\n",
    "    for u, v, data in network.edges(data=True):\n",
    "        e = A.get_edge(u, v)\n",
    "        e.attr['label'] = data.get('transition', '')\n",
    "\n",
    "    # Визуализация\n",
    "    A.draw('graph.png', prog='dot', format='png')\n",
    "    display(Image('graph.png'))\n",
    "\n",
    "    return is_bounded"
   ],
   "id": "2deeea467b409f4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "vizualizeGraph_graphviz(cg)",
   "id": "cedd16a0d5ff8933",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "vizualizeGraph_graphviz(rg)",
   "id": "14766053e10a0168",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pm4py.objects.petri_net.utils import petri_utils\n",
    "from pm4py.objects.petri_net.exporter import exporter as pnml_exporter\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "\n",
    "from pm4py.objects.petri_net.obj import PetriNet, Marking\n",
    "\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "# делаем копию сети\n",
    "net_copy = copy.deepcopy(net)\n",
    "\n",
    "\n",
    "\n",
    "# добавляем X - переход и проверяем на ограниченность\n",
    "\n",
    "def add_cycle_transition(pn: PetriNet, first_place: PetriNet.Place, last_place: PetriNet.Place):\n",
    "    \"\"\"\n",
    "    Добавляет переход, который берёт токен из последнего места\n",
    "    и кладёт его в первое место.\n",
    "    \"\"\"\n",
    "    # создаём переход\n",
    "    t_cycle = PetriNet.Transition(\"t_cycle\", \"t_cycle\")\n",
    "\n",
    "    # добавляем переход в сеть\n",
    "    pn.transitions.add(t_cycle)\n",
    "\n",
    "    # дуги: last_place → t_cycle → first_place\n",
    "    petri_utils.add_arc_from_to(last_place, t_cycle, pn)\n",
    "    petri_utils.add_arc_from_to(t_cycle, first_place, pn)\n",
    "    return t_cycle\n",
    "\n",
    "\n",
    "#вычисляем начальные и конечные позиции\n",
    "begin_places = [place for place, tokens in im.items() if tokens > 0]\n",
    "\n",
    "final_places = [place for place, tokens in fm.items() if tokens > 0]\n",
    "\n",
    "# создаём переход\n",
    "t_cycle = PetriNet.Transition(\"t_cycle\", \"t_cycle\")\n",
    "\n",
    "# добавляем переход в сеть\n",
    "net_copy.transitions.add(t_cycle)\n",
    "\n",
    "\n",
    "#получить реальную позицию (объект) по ключу из маркировки\n",
    "\n",
    "def get_place_by_name(pn, name):\n",
    "    for place in pn.places:\n",
    "        if place.name == name:\n",
    "            return place\n",
    "    return None  # если места с таким именем нет\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p_fin = next(iter(fm.keys()))   # объект Place\n",
    "p_beg = next(iter(im.keys()))   # объект Place\n",
    "p_Fin = get_place_by_name (net_copy, p_fin.name)\n",
    "p_Beg = get_place_by_name (net_copy, p_beg.name)\n",
    "\n",
    "\n",
    "#добавляем дуги\n",
    "petri_utils.add_arc_from_to(p_Fin, t_cycle, net_copy)\n",
    "petri_utils.add_arc_from_to( t_cycle,p_Beg, net_copy)\n",
    "\n",
    "\n",
    "#покажем расширенную сетку\n",
    "gviz = pn_visualizer.apply(\n",
    "    net_copy,\n",
    "    im,\n",
    "    fm,\n",
    "    parameters={\"debug\": True, \"set_rankdir\": \"LR\"} # set_rankdir for horizontal layout\n",
    ")\n",
    "\n",
    "# отобразим\n",
    "pn_visualizer.view(gviz)\n",
    "\n",
    "\n",
    "# строим граф покрытия маркировок расширенной сети  и там же проверяем на ограниченность (нет омег)\n",
    "\n",
    "cg_ext=minimal_coverability_graph.apply(net_copy, initial_marking, final_marking)\n",
    "is_bounded=vizualizeGraph_graphviz(cg_ext)\n",
    "print(\"Is bounded?:\",is_bounded)"
   ],
   "id": "da71a32002361bf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Анализ бездефектности (Woflan) и дополнительные проверки",
   "id": "c6a3e19ad17f33e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "is_sound_result = woflan.apply(net, initial_marking, final_marking, \n",
    "                                parameters={\n",
    "                                    woflan.Parameters.RETURN_ASAP_WHEN_NOT_SOUND: True,\n",
    "                                    woflan.Parameters.PRINT_DIAGNOSTICS: True,\n",
    "                                    woflan.Parameters.RETURN_DIAGNOSTICS: True\n",
    "                                })\n",
    "\n",
    "print(f\"Сеть Петри является корректной (бездефектной): {is_sound_result[0]}\")\n",
    "\n",
    "# Проверка ограниченности сети через граф достижимости\n",
    "print(f\"1. Проверка ограниченности:\")\n",
    "print(f\"Количество состояний в графе достижимости: {len(ts.states)}\")\n",
    "\n",
    "if len(ts.states) < 1000:\n",
    "    print(f\"Сеть ограничена (конечное число состояний)\")\n",
    "    is_bounded = True\n",
    "else:\n",
    "    print(f\"Сеть может быть неограниченной\")\n",
    "    is_bounded = False\n",
    "\n",
    "# Построение расширенной сети для проверки живости\n",
    "print(f\"\\n2. Проверка живости сети:\")\n",
    "\n",
    "# Преобразуем граф достижимости в NetworkX для анализа сильносвязных компонент\n",
    "try:\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    for state in ts.states:\n",
    "        G.add_node(str(state))\n",
    "    \n",
    "    for transition in ts.transitions:\n",
    "        G.add_edge(str(transition.from_state), str(transition.to_state))\n",
    "    \n",
    "    # Находим сильносвязные компоненты (алгоритм Косарайю)\n",
    "    scc = list(nx.strongly_connected_components(G))\n",
    "    \n",
    "    print(f\"Найдено {len(scc)} сильносвязных компонент\")\n",
    "    \n",
    "    all_transitions = set([t.name for t in net.transitions])\n",
    "    \n",
    "    # Для живости сети должна быть одна компонента, содержащая все переходы\n",
    "    if len(scc) == 1:\n",
    "        print(f\"раф достижимости сильносвязный\")\n",
    "        is_live = True\n",
    "    else:\n",
    "        # Проверяем, есть ли компонента, которая достижима из всех других\n",
    "        print(f\"Граф достижимости не является сильносвязным\")\n",
    "        \n",
    "        # Находим компоненты, которые являются стоками (терминальными SCC)\n",
    "        condensation = nx.condensation(G)\n",
    "        terminal_scc = [node for node in condensation.nodes() if condensation.out_degree(node) == 0]\n",
    "        \n",
    "        if len(terminal_scc) == 1:\n",
    "            print(f\"Найдена одна терминальная SCC\")\n",
    "            is_live = True\n",
    "        else:\n",
    "            print(f\"Найдено {len(terminal_scc)} терминальных SCC\")\n",
    "            is_live = False\n",
    "    \n",
    "    print(f\"\\n3. Проверка по теореме о бездефектности:\")\n",
    "    print(f\"Сеть ограничена: {is_bounded}\")\n",
    "    print(f\"Сеть живая: {is_live}\")\n",
    "    \n",
    "    if is_bounded and is_live:\n",
    "        print(f\"ВЫВОД: Сеть является бездефектной (по теореме)\")\n",
    "    else:\n",
    "        print(f\"ВЫВОД: Сеть не является бездефектной (по теореме)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при анализе SCC: {e}\")\n",
    "    print(\"Продолжаем анализ через другие методы\")"
   ],
   "id": "988266012ebf33ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "net, initial_marking, final_marking = convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "from pm4py.algo.analysis.woflan import algorithm as woflan\n",
    "\n",
    "is_sound = woflan.apply(net, initial_marking, final_marking, parameters={woflan.Parameters.RETURN_ASAP_WHEN_NOT_SOUND: True,\n",
    "                                                     woflan.Parameters.PRINT_DIAGNOSTICS: True,\n",
    "\n",
    "                                                     woflan.Parameters.RETURN_DIAGNOSTICS: True})\n",
    "\n",
    "print(\"\\nIs Workflow net sound? ->\", is_sound[0])\n",
    "\n",
    "print(\"\\n Полная статистика\",is_sound[1])\n"
   ],
   "id": "139002eefc4c4faa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Генерация журнала событий",
   "id": "6e4d2af1e4ec97b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "simulated_log = simulator.apply(net, initial_marking,\n",
    "                                variant=simulator.Variants.BASIC_PLAYOUT,\n",
    "                                parameters={simulator.Variants.BASIC_PLAYOUT.value.Parameters.NO_TRACES: 50})\n",
    "\n",
    "# Сохранение сгенерированного журнала\n",
    "write_xes(simulated_log, 'generated_log.xes')\n",
    "\n",
    "dataframe = convert_to_dataframe(simulated_log)\n",
    "dataframe.to_csv('generated_log.csv', index=False)\n",
    "\n",
    "print(f\"Количество трасс: {len(simulated_log)}\")\n",
    "print(f\"Общее количество событий: {len(dataframe)}\")"
   ],
   "id": "dbac473304611d09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "simulated_log = simulator.apply(net, initial_marking, variant=simulator.Variants.BASIC_PLAYOUT,\n",
    "                                    parameters={simulator.Variants.BASIC_PLAYOUT.value.Parameters.NO_TRACES: 50})\n",
    "\n",
    "write_xes(simulated_log, 'log.xes')\n",
    "\n",
    "gviz = pn_visualizer.apply(net, initial_marking, final_marking)\n",
    "pn_visualizer.view(gviz)\n",
    "\n",
    "dataframe = convert_to_dataframe(simulated_log)\n",
    "dataframe.to_csv('exp.csv')\n"
   ],
   "id": "1a7bbc21d69975e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"exp.csv\", index_col=0)\n",
    "df = df.rename(columns={\"case:concept:name\": \"client\", \"time:timestamp\": \"datetime\", \"concept:name\": \"action\"})\n",
    "df['resource']=''\n",
    "df.head(20)"
   ],
   "id": "f132063fd443bc4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Предварительный анализ журнала событий",
   "id": "d3a18ef91a895b84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"generated_log.csv\")\n",
    "\n",
    "# Переименование столбцов для удобства\n",
    "df = df.rename(columns={\n",
    "    \"case:concept:name\": \"case_id\",\n",
    "    \"time:timestamp\": \"datetime\",\n",
    "    \"concept:name\": \"activity\"\n",
    "})\n",
    "\n",
    "# Преобразование даты\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Определение ресурсов для каждого действия на основе BPMN процесса\n",
    "applicant_activities = ['Получение разрешения заявителем', 'Исправление замечаний по проекту']\n",
    "clerk_activities = ['Первичная проверка документов', 'Рассмотрение заместителем руководителя']\n",
    "architect_activities = ['Проверка архитектором-экспертом', 'Ручная проверка архитектора-эксперта']\n",
    "engineer_activities = ['Проверка инженером-экспертом', 'Проверка инженером экспертом']\n",
    "fire_service_activities = ['Запрос заключения пожарного эксперта', 'Ручная проверка пожарного надзора']\n",
    "sanepidemic_activities = ['Запрос заключения санитарно-эпидемиологической службы',\n",
    "                          'Проверка санэпидем надзором', 'Медкомиссия']\n",
    "supervisor_activities = ['Рассмотрение руководителем']\n",
    "\n",
    "# Назначение ресурсов\n",
    "df['resource'] = 'Система/Процесс'  # Значение по умолчанию\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    activity = str(row['activity'])\n",
    "\n",
    "    if any(act in activity for act in applicant_activities):\n",
    "        df.at[idx, 'resource'] = 'Заявитель'\n",
    "    elif any(act in activity for act in clerk_activities):\n",
    "        df.at[idx, 'resource'] = 'Служащий'\n",
    "    elif any(act in activity for act in architect_activities):\n",
    "        df.at[idx, 'resource'] = 'Архитектор'\n",
    "    elif any(act in activity for act in engineer_activities):\n",
    "        df.at[idx, 'resource'] = 'Инженер'\n",
    "    elif any(act in activity for act in fire_service_activities):\n",
    "        df.at[idx, 'resource'] = 'Пожарный надзор'\n",
    "    elif any(act in activity for act in sanepidemic_activities):\n",
    "        df.at[idx, 'resource'] = 'Санэпидемнадзор'\n",
    "    elif any(act in activity for act in supervisor_activities):\n",
    "        df.at[idx, 'resource'] = 'Руководитель'\n",
    "\n",
    "print(\"Журнал событий обработан\")\n",
    "print(f\"Размерность данных: {df.shape[0]} строк, {df.shape[1]} столбцов\")\n",
    "print(f\"\\nРаспределение событий по ресурсам:\")\n",
    "print(df['resource'].value_counts())\n",
    "\n",
    "# Сохранение обработанного журнала\n",
    "df.to_csv('processed_log.csv', index=False)\n",
    "print(\"\\nОбработанный журнал сохранен в 'processed_log.csv'\")"
   ],
   "id": "ad07b31723bbd6c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Временной анализ журнала событий",
   "id": "e5b202d97cc6bae7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "events = df.copy()\n",
    "\n",
    "case_starts_ends = events.groupby('case_id')['datetime'].agg(['min', 'max']).reset_index()\n",
    "case_starts_ends.columns = ['case_id', 'casestart', 'caseend']\n",
    "\n",
    "events = events.merge(case_starts_ends, on='case_id')\n",
    "\n",
    "# Расчет относительного времени\n",
    "events['relativetime'] = events['caseend'] - events['casestart']\n",
    "events['relativetime_s'] = events['relativetime'].dt.total_seconds()\n",
    "events['relativedays'] = events['relativetime'].dt.days\n",
    "\n",
    "# Дополнительные временные характеристики\n",
    "events['weekday'] = events['datetime'].dt.weekday\n",
    "events['date'] = events['datetime'].dt.date\n",
    "events['startdate'] = events['casestart'].dt.date\n",
    "events['hour'] = events['datetime'].dt.hour\n",
    "\n",
    "print(f\"\\nСтатистика длительности кейсов:\")\n",
    "case_durations = events.groupby('case_id')['relativetime_s'].max()\n",
    "print(f\"Минимальная длительность: {case_durations.min():.0f} сек ({case_durations.min()/60:.1f} мин)\")\n",
    "print(f\"Максимальная длительность: {case_durations.max():.0f} сек ({case_durations.max()/60:.1f} мин)\")\n",
    "print(f\"Средняя длительность: {case_durations.mean():.0f} сек ({case_durations.mean()/60:.1f} мин)\")\n",
    "print(f\"Медианная длительность: {case_durations.median():.0f} сек ({case_durations.median()/60:.1f} мин)\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(case_durations, bins=20, kde=True)\n",
    "plt.title('Распределение длительности кейсов')\n",
    "plt.xlabel('Длительность (секунды)')\n",
    "plt.ylabel('Количество кейсов')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ],
   "id": "d826e6101f5d6ca0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Визуализация журнала событий",
   "id": "ddc576979829ffe8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. Реконструкция процесса алгоритмом Alpha Miner",
   "id": "43b87e459d7cc122"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "log_for_mining = read_xes('generated_log.xes')\n",
    "\n",
    "net_alpha, im_alpha, fm_alpha = alpha_miner.apply(log_for_mining)\n",
    "\n",
    "parameters = {pn_visualizer.Variants.FREQUENCY.value.Parameters.FORMAT: \"png\"}\n",
    "gviz_alpha = pn_visualizer.apply(net_alpha, im_alpha, fm_alpha,\n",
    "                                 parameters=parameters,\n",
    "                                 variant=pn_visualizer.Variants.FREQUENCY,\n",
    "                                 log=log_for_mining)\n",
    "pn_visualizer.view(gviz_alpha)\n",
    "\n",
    "print(f\"Реконструированная сеть Петри:\")\n",
    "print(f\"  - Переходов: {len(net_alpha.transitions)}\")\n",
    "print(f\"  - Позиций: {len(net_alpha.places)}\")"
   ],
   "id": "64663b3356a3353e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9. Реконструкция процесса алгоритмом Alpha+ Miner",
   "id": "df5ce38f5b32186c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "net_alpha_plus, im_alpha_plus, fm_alpha_plus = discover_petri_net_alpha_plus(log_for_mining)\n",
    "\n",
    "# Визуализация\n",
    "gviz_alpha_plus = pn_visualizer.apply(net_alpha_plus, im_alpha_plus, fm_alpha_plus,\n",
    "                                      parameters=parameters,\n",
    "                                      variant=pn_visualizer.Variants.FREQUENCY,\n",
    "                                      log=log_for_mining)\n",
    "pn_visualizer.view(gviz_alpha_plus)\n",
    "\n",
    "print(f\"Реконструированная сеть Петри:\")\n",
    "print(f\"  - Переходов: {len(net_alpha_plus.transitions)}\")\n",
    "print(f\"  - Позиций: {len(net_alpha_plus.places)}\")"
   ],
   "id": "22c9d44b684cadb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10. Реконструкция процесса алгоритмом Heuristics Miner",
   "id": "c3c6d53dac4ef0e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "heu_net = heuristics_miner.apply_heu(log_for_mining)\n",
    "\n",
    "gviz_heu = hn_visualizer.apply(heu_net)\n",
    "hn_visualizer.view(gviz_heu)\n",
    "\n",
    "net_heu, im_heu, fm_heu = heuristics_miner.apply(log_for_mining)\n",
    "\n",
    "gviz_heu_pn = pn_visualizer.apply(net_heu, im_heu, fm_heu)\n",
    "pn_visualizer.view(gviz_heu_pn)\n",
    "\n",
    "print(f\"Сеть Петри из Heuristics Miner:\")\n",
    "print(f\"  - Переходов: {len(net_heu.transitions)}\")\n",
    "print(f\"  - Позиций: {len(net_heu.places)}\")"
   ],
   "id": "ffff92716e083c93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 11. Реконструкция процесса алгоритмом Inductive Miner",
   "id": "7d7ba9b8d9421bdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "tree = inductive_miner.apply(log_for_mining)\n",
    "\n",
    "gviz_tree = pt_visualizer.apply(tree)\n",
    "pt_visualizer.view(gviz_tree)\n",
    "\n",
    "net_ind, im_ind, fm_ind = pt_converter.apply(tree)\n",
    "\n",
    "print(f\"Сеть Петри из Inductive Miner:\")\n",
    "print(f\"  - Переходов: {len(net_ind.transitions)}\")\n",
    "print(f\"  - Позиций: {len(net_ind.places)}\")"
   ],
   "id": "150590fb8108f940",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12. Оценка качества реконструкции (Token-based Replay)",
   "id": "e74bcabe4c2e14f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "replayed_traces_alpha = conformance_diagnostics_token_based_replay.apply(\n",
    "    log_for_mining, net_alpha, im_alpha, fm_alpha)\n",
    "\n",
    "# Оценка качества для Heuristics Miner\n",
    "replayed_traces_heu = conformance_diagnostics_token_based_replay.apply(\n",
    "    log_for_mining, net_heu, im_heu, fm_heu)\n",
    "\n",
    "# Оценка качества для Inductive Miner\n",
    "replayed_traces_ind = conformance_diagnostics_token_based_replay.apply(\n",
    "    log_for_mining, net_ind, im_ind, fm_ind)\n",
    "\n",
    "def analyze_replay_results(replayed_traces, algorithm_name):\n",
    "    total_traces = len(replayed_traces)\n",
    "    fitting_traces = sum(1 for trace in replayed_traces if trace.get('trace_is_fit', False))\n",
    "    percent_fitting = (fitting_traces / total_traces * 100) if total_traces > 0 else 0\n",
    "    \n",
    "    # Среднее количество недостающих токенов\n",
    "    missing_tokens = np.mean([trace.get('missing_tokens', 0) for trace in replayed_traces])\n",
    "    # Среднее количество оставшихся токенов\n",
    "    remaining_tokens = np.mean([trace.get('remaining_tokens', 0) for trace in replayed_traces])\n",
    "    # Среднее количество продуцированных токенов\n",
    "    produced_tokens = np.mean([trace.get('produced_tokens', 0) for trace in replayed_traces])\n",
    "    \n",
    "    return {\n",
    "        'algorithm': algorithm_name,\n",
    "        'total_traces': total_traces,\n",
    "        'fitting_traces': fitting_traces,\n",
    "        'percent_fitting': percent_fitting,\n",
    "        'missing_tokens': missing_tokens,\n",
    "        'remaining_tokens': remaining_tokens,\n",
    "        'produced_tokens': produced_tokens\n",
    "    }\n",
    "\n",
    "results = [\n",
    "    analyze_replay_results(replayed_traces_alpha, \"Alpha Miner\"),\n",
    "    analyze_replay_results(replayed_traces_heu, \"Heuristics Miner\"),\n",
    "    analyze_replay_results(replayed_traces_ind, \"Inductive Miner\")\n",
    "]\n",
    "\n",
    "for result in results:\n",
    "    print(f\"\\n{result['algorithm']}:\")\n",
    "    print(f\"Соответствующих трасс: {result['fitting_traces']}/{result['total_traces']} ({result['percent_fitting']:.1f}%)\")\n",
    "    print(f\"Среднее недостающих токенов: {result['missing_tokens']:.2f}\")\n",
    "    print(f\"Среднее оставшихся токенов: {result['remaining_tokens']:.2f}\")\n",
    "    print(f\"Среднее продуцированных токенов: {result['produced_tokens']:.2f}\")"
   ],
   "id": "a8173941b249ef42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 13. Вычисление метрик качества реконструкции (Fitness)",
   "id": "bf3d51f1a661f3e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "log_fitness_alpha = replay_fitness.evaluate(replayed_traces_alpha,\n",
    "                                            variant=replay_fitness.Variants.TOKEN_BASED)\n",
    "log_fitness_heu = replay_fitness.evaluate(replayed_traces_heu,\n",
    "                                          variant=replay_fitness.Variants.TOKEN_BASED)\n",
    "log_fitness_ind = replay_fitness.evaluate(replayed_traces_ind,\n",
    "                                          variant=replay_fitness.Variants.TOKEN_BASED)\n",
    "\n",
    "print(\"=== Метрики Fitness (соответствие модели журналу) ===\")\n",
    "\n",
    "fitness_summary = pd.DataFrame({\n",
    "    'Алгоритм': ['Alpha Miner', 'Heuristics Miner', 'Inductive Miner'],\n",
    "    'fitness': [\n",
    "        log_fitness_alpha.get('average_trace_fitness', 0),\n",
    "        log_fitness_heu.get('average_trace_fitness', 0),\n",
    "        log_fitness_ind.get('average_trace_fitness', 0)\n",
    "    ],\n",
    "    'percentage_fit_traces': [\n",
    "        log_fitness_alpha.get('percentage_of_fitting_traces', 0),\n",
    "        log_fitness_heu.get('percentage_of_fitting_traces', 0),\n",
    "        log_fitness_ind.get('percentage_of_fitting_traces', 0)\n",
    "    ],\n",
    "    'log_fitness': [\n",
    "        log_fitness_alpha.get('log_fitness', 0),\n",
    "        log_fitness_heu.get('log_fitness', 0),\n",
    "        log_fitness_ind.get('log_fitness', 0)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(fitness_summary.to_string(index=False))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_pos = np.arange(len(fitness_summary))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = plt.bar(x_pos - width, fitness_summary['fitness'], width,\n",
    "                label='Fitness (среднее)', color='skyblue')\n",
    "bars2 = plt.bar(x_pos, fitness_summary['percentage_fit_traces']/100, width,\n",
    "                label='% подходящих трасс', color='lightgreen')\n",
    "bars3 = plt.bar(x_pos + width, fitness_summary['log_fitness'], width,\n",
    "                label='Log Fitness', color='salmon')\n",
    "\n",
    "plt.title('Сравнение метрик качества реконструкции', fontsize=14, pad=15)\n",
    "plt.xlabel('Алгоритм')\n",
    "plt.ylabel('Значение метрики')\n",
    "plt.xticks(x_pos, fitness_summary['Алгоритм'])\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_idx = fitness_summary['fitness'].idxmax()\n",
    "best_algorithm = fitness_summary.loc[best_idx, 'Алгоритм']\n",
    "best_fitness = fitness_summary.loc[best_idx, 'fitness']\n",
    "\n",
    "print(f\"\\nВЫВОД: Наилучший результат показал {best_algorithm} с fitness = {best_fitness:.3f}\")"
   ],
   "id": "b28ed909e9aacc0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 14. Дополнительный анализ: построение дерева покрытия маркировок расширенной сети",
   "id": "4c1b2d27028ea5c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"=== Дополнительный анализ: дерево покрытия маркировок расширенной сети ===\")\n",
    "\n",
    "try:\n",
    "    # Импортируем необходимые функции\n",
    "    from pm4py.objects.petri_net.utils.petri_utils import add_arc_from_to\n",
    "\n",
    "    # Создаем копию сети для экспериментов\n",
    "    from pm4py.objects.petri_net.obj import PetriNet, Marking\n",
    "\n",
    "    # Создаем расширенную сеть (добавляем переход из конечной в начальную позицию)\n",
    "    extended_net = PetriNet()\n",
    "\n",
    "    # Копируем все элементы из исходной сети\n",
    "    place_map = {}\n",
    "    for place in net.places:\n",
    "        new_place = PetriNet.Place(place.name)\n",
    "        extended_net.places.add(new_place)\n",
    "        place_map[place] = new_place\n",
    "\n",
    "    transition_map = {}\n",
    "    for transition in net.transitions:\n",
    "        new_transition = PetriNet.Transition(transition.name, transition.label)\n",
    "        extended_net.transitions.add(new_transition)\n",
    "        transition_map[transition] = new_transition\n",
    "\n",
    "    # Копируем дуги\n",
    "    for arc in net.arcs:\n",
    "        if arc.source in place_map and arc.target in transition_map:\n",
    "            add_arc_from_to(place_map[arc.source], transition_map[arc.target], extended_net)\n",
    "        elif arc.source in transition_map and arc.target in place_map:\n",
    "            add_arc_from_to(transition_map[arc.source], place_map[arc.target], extended_net)\n",
    "\n",
    "    # Создаем начальную маркировку для расширенной сети\n",
    "    extended_im = Marking()\n",
    "    for place, marking in initial_marking.items():\n",
    "        if place in place_map:\n",
    "            extended_im[place_map[place]] = marking\n",
    "\n",
    "    # Добавляем дополнительный переход из конечной в начальную позицию\n",
    "    # Находим начальную и конечную позиции\n",
    "    start_place = None\n",
    "    end_place = None\n",
    "\n",
    "    # Сначала ищем по ключевым словам в именах\n",
    "    for place in extended_net.places:\n",
    "        place_name_lower = place.name.lower()\n",
    "        if any(keyword in place_name_lower for keyword in ['start', 'начал', 'источник', 'source']):\n",
    "            start_place = place\n",
    "        if any(keyword in place_name_lower for keyword in ['end', 'конеч', 'финиш', 'sink']):\n",
    "            end_place = place\n",
    "\n",
    "    # Если не нашли по имени, пробуем другие стратегии\n",
    "    if start_place is None:\n",
    "        # Ищем позиции, которые есть в начальной маркировке\n",
    "        for place in extended_net.places:\n",
    "            if place in extended_im:\n",
    "                start_place = place\n",
    "                break\n",
    "\n",
    "    if end_place is None:\n",
    "        # Ищем позиции, которые имеют много исходящих дуг\n",
    "        max_outgoing = 0\n",
    "        for place in extended_net.places:\n",
    "            outgoing_count = sum(1 for arc in extended_net.arcs if arc.source == place)\n",
    "            if outgoing_count > max_outgoing:\n",
    "                max_outgoing = outgoing_count\n",
    "                end_place = place\n",
    "\n",
    "    # Если все еще не нашли, берем первую и последнюю\n",
    "    if start_place is None:\n",
    "        start_place = list(extended_net.places)[0]\n",
    "    if end_place is None:\n",
    "        end_place = list(extended_net.places)[-1]\n",
    "\n",
    "    print(f\"Выбраны позиции для добавления reset перехода:\")\n",
    "    print(f\"  - Начальная позиция: {start_place.name}\")\n",
    "    print(f\"  - Конечная позиция: {end_place.name}\")\n",
    "\n",
    "    # Создаем переход \"reset\"\n",
    "    reset_transition = PetriNet.Transition(\"reset_transition\", \"reset\")\n",
    "    extended_net.transitions.add(reset_transition)\n",
    "\n",
    "    # Добавляем дуги: end_place -> reset_transition -> start_place\n",
    "    add_arc_from_to(end_place, reset_transition, extended_net)\n",
    "    add_arc_from_to(reset_transition, start_place, extended_net)\n",
    "\n",
    "    print(f\"\\nРасширенная сеть создана:\")\n",
    "    print(f\"  - Переходов: {len(extended_net.transitions)} (включая reset)\")\n",
    "    print(f\"  - Позиций: {len(extended_net.places)}\")\n",
    "    print(f\"  - Добавлен переход 'reset' из {end_place.name} в {start_place.name}\")\n",
    "\n",
    "    # Визуализируем расширенную сеть\n",
    "    gviz_extended = pn_visualizer.apply(extended_net, extended_im, Marking())\n",
    "    pn_visualizer.view(gviz_extended)\n",
    "\n",
    "    # Строим граф достижимости для расширенной сети\n",
    "    print(\"\\nСтроим граф достижимости для расширенной сети...\")\n",
    "    extended_ts = reachability_graph.construct_reachability_graph(extended_net, extended_im)\n",
    "\n",
    "    print(f\"\\nГраф достижимости расширенной сети:\")\n",
    "    print(f\"  - Количество состояний: {len(extended_ts.states)}\")\n",
    "    print(f\"  - Количество переходов: {len(extended_ts.transitions)}\")\n",
    "\n",
    "    # Визуализируем граф достижимости\n",
    "    gviz_extended_ts = ts_visualizer.apply(\n",
    "        extended_ts,\n",
    "        parameters={ts_visualizer.Variants.VIEW_BASED.value.Parameters.FORMAT: \"png\"}\n",
    "    )\n",
    "    ts_visualizer.view(gviz_extended_ts)\n",
    "\n",
    "    # Проверяем, является ли граф достижимости конечным (ограниченность)\n",
    "    if len(extended_ts.states) < 1000:\n",
    "        print(f\"  - Граф достижимости конечный -> сеть ограничена\")\n",
    "\n",
    "        # Преобразуем граф достижимости в NetworkX для анализа сильносвязных компонент\n",
    "        G_extended = nx.DiGraph()\n",
    "\n",
    "        # Добавляем узлы (состояния)\n",
    "        for state in extended_ts.states:\n",
    "            G_extended.add_node(str(state))\n",
    "\n",
    "        # Добавляем ребра (переходы)\n",
    "        for transition in extended_ts.transitions:\n",
    "            G_extended.add_edge(str(transition.from_state), str(transition.to_state))\n",
    "\n",
    "        # Находим сильносвязные компоненты с помощью алгоритма Косарайю\n",
    "        scc_extended = list(nx.strongly_connected_components(G_extended))\n",
    "\n",
    "        print(f\"\\nАнализ сильносвязных компонент (SCC):\")\n",
    "        print(f\"  - Количество SCC: {len(scc_extended)}\")\n",
    "\n",
    "        # Выводим размеры компонент\n",
    "        for i, component in enumerate(scc_extended, 1):\n",
    "            print(f\"    SCC {i}: {len(component)} состояний\")\n",
    "\n",
    "        # Проверяем условия живости\n",
    "        if len(scc_extended) == 1:\n",
    "            print(f\"  - Граф достижимости сильносвязный\")\n",
    "            print(f\"  - УСЛОВИЕ 1: Выполнено (граф сильносвязный)\")\n",
    "            print(f\"  - УСЛОВИЕ 2: Выполнено (ограниченность подтверждена)\")\n",
    "            print(f\"\\nВЫВОД ДЛЯ РАСШИРЕННОЙ СЕТИ: ограниченная и живая -> БЕЗДЕФЕКТНАЯ\")\n",
    "\n",
    "            # Дополнительная проверка: все ли переходы присутствуют в SCC\n",
    "            all_nodes = set(G_extended.nodes())\n",
    "            if len(scc_extended[0]) == len(all_nodes):\n",
    "                print(f\"  - ДОПОЛНИТЕЛЬНО: Все состояния в одной SCC\")\n",
    "        else:\n",
    "            # Проверяем, есть ли доминирующая SCC, содержащая все важные состояния\n",
    "            all_nodes = set(G_extended.nodes())\n",
    "            largest_scc = max(scc_extended, key=len)\n",
    "\n",
    "            print(f\"\\nАнализ наибольшей SCC:\")\n",
    "            print(f\"  - Размер наибольшей SCC: {len(largest_scc)} из {len(all_nodes)} состояний\")\n",
    "            print(f\"  - Покрытие: {len(largest_scc)/len(all_nodes)*100:.1f}%\")\n",
    "\n",
    "            # Проверяем, достижима ли наибольшая SCC из всех состояний\n",
    "            # Для этого строим конденсацию графа\n",
    "            condensation = nx.condensation(G_extended)\n",
    "\n",
    "            # Находим компоненты-стоки (терминальные SCC)\n",
    "            terminal_scc_indices = [node for node in condensation.nodes()\n",
    "                                   if condensation.out_degree(node) == 0]\n",
    "\n",
    "            print(f\"  - Количество терминальных SCC: {len(terminal_scc_indices)}\")\n",
    "\n",
    "            if len(terminal_scc_indices) == 1:\n",
    "                print(f\"  - УСЛОВИЕ 1: Выполнено (одна терминальная SCC)\")\n",
    "                print(f\"  - УСЛОВИЕ 2: Выполнено (ограниченность подтверждена)\")\n",
    "                print(f\"\\nВЫВОД ДЛЯ РАСШИРЕННОЙ СЕТИ: ограниченная и живая -> БЕЗДЕФЕКТНАЯ\")\n",
    "            else:\n",
    "                print(f\"  - УСЛОВИЕ 1: Не выполнено (несколько терминальных SCC)\")\n",
    "                print(f\"  - УСЛОВИЕ 2: Выполнено (ограниченность подтверждена)\")\n",
    "                print(f\"\\nВЫВОД ДЛЯ РАСШИРЕННОЙ СЕТИ: ограниченная, но не живая\")\n",
    "    else:\n",
    "        print(f\"  - Граф достижимости содержит {len(extended_ts.states)} состояний\")\n",
    "        print(f\"  - Возможно, сеть неограниченная или слишком сложная для полного анализа\")\n",
    "\n",
    "        # Пробуем проанализировать первые несколько состояний\n",
    "        print(f\"\\nАнализ первых 100 состояний:\")\n",
    "        sample_states = list(extended_ts.states)[:100]\n",
    "\n",
    "        # Создаем частичный граф для анализа\n",
    "        G_partial = nx.DiGraph()\n",
    "        for state in sample_states:\n",
    "            G_partial.add_node(str(state))\n",
    "\n",
    "        # Добавляем переходы между этими состояниями\n",
    "        for transition in extended_ts.transitions:\n",
    "            if str(transition.from_state) in G_partial and str(transition.to_state) in G_partial:\n",
    "                G_partial.add_edge(str(transition.from_state), str(transition.to_state))\n",
    "\n",
    "        # Анализируем частичный граф\n",
    "        if len(G_partial.nodes()) > 0:\n",
    "            scc_partial = list(nx.strongly_connected_components(G_partial))\n",
    "            print(f\"  - Количество SCC в выборке: {len(scc_partial)}\")\n",
    "\n",
    "            if len(scc_partial) > 0:\n",
    "                largest_scc = max(scc_partial, key=len)\n",
    "                print(f\"  - Размер наибольшей SCC в выборке: {len(largest_scc)} состояний\")\n",
    "\n",
    "        print(f\"\\nВЫВОД ДЛЯ РАСШИРЕННОЙ СЕТИ: требуется дополнительный анализ (возможно неограниченная)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при построении расширенной сети: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"Продолжаем без дополнительного анализа расширенной сети\")"
   ],
   "id": "3bd57959301e1197",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 16. Анализ Directly Follows Graph (DFG)",
   "id": "c0a218037019dc9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from pm4py.algo.discovery.dfg import algorithm as dfg_discovery\n",
    "from pm4py.visualization.dfg import visualizer as dfg_visualization\n",
    "\n",
    "dfg = dfg_discovery.apply(log_for_mining, variant=dfg_discovery.Variants.PERFORMANCE)\n",
    "\n",
    "print(f\"Количество связей между событиями: {len(dfg)}\")\n",
    "\n",
    "gviz_dfg_freq = dfg_visualization.apply(\n",
    "    dfg,\n",
    "    log=log_for_mining,\n",
    "    variant=dfg_visualization.Variants.FREQUENCY,\n",
    "    parameters={\"format\": \"png\"}\n",
    ")\n",
    "dfg_visualization.view(gviz_dfg_freq)\n",
    "\n",
    "gviz_dfg_perf = dfg_visualization.apply(\n",
    "    dfg,\n",
    "    log=log_for_mining,\n",
    "    variant=dfg_visualization.Variants.PERFORMANCE,\n",
    "    parameters={\"format\": \"png\"}\n",
    ")\n",
    "dfg_visualization.view(gviz_dfg_perf)\n",
    "\n",
    "# Сортируем связи по частоте\n",
    "sorted_dfg = sorted(dfg.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "print(\"\\n=== Анализ степени связности событий ===\")\n",
    "\n",
    "in_degree = {}\n",
    "out_degree = {}\n",
    "\n",
    "for (source, target), count in dfg.items():\n",
    "    out_degree[source] = out_degree.get(source, 0) + count\n",
    "    in_degree[target] = in_degree.get(target, 0) + count\n",
    "\n",
    "print(\"\\nСобытия с наибольшим числом исходящих связей (инициаторы):\")\n",
    "sorted_out = sorted(out_degree.items(), key=lambda x: x[1], reverse=True)\n",
    "for event, count in sorted_out[:5]:\n",
    "    print(f\"  {event:40}: {count:4} исходящих связей\")\n",
    "\n",
    "print(\"\\nСобытия с наибольшим числом входящих связей (завершители):\")\n",
    "sorted_in = sorted(in_degree.items(), key=lambda x: x[1], reverse=True)\n",
    "for event, count in sorted_in[:5]:\n",
    "    print(f\"  {event:40}: {count:4} входящих связей\")\n",
    "\n",
    "# Построение DFG как промежуточного шага для Heuristics Miner\n",
    "# Heuristics Miner использует DFG для вычисления зависимостей\n",
    "from pm4py.algo.discovery.heuristics.algorithm import HeuristicsNet\n",
    "\n",
    "heu_net_from_dfg = HeuristicsNet(dfg)\n",
    "\n",
    "gviz_heu_dfg = hn_visualizer.apply(heu_net_from_dfg)\n",
    "hn_visualizer.view(gviz_heu_dfg)\n",
    "\n",
    "\n",
    "# Вычисляем матрицу зависимости для Heuristics Miner\n",
    "dependency_matrix = heu_net_from_dfg.dependency_matrix\n",
    "\n",
    "print(\"Примеры сильных зависимостей между событиями (значение > 0.8):\")\n",
    "strong_dependencies = []\n",
    "\n",
    "for (source, target), value in dependency_matrix.items():\n",
    "    if value > 0.8 and source != target:\n",
    "        strong_dependencies.append(((source, target), value))\n",
    "\n",
    "strong_dependencies.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, ((source, target), value) in enumerate(strong_dependencies[:10], 1):\n",
    "    print(f\"{i:2}. {source:30} -> {target:30}: зависимость = {value:.3f}\")\n",
    "\n",
    "# Визуализация DFG с помощью NetworkX для дополнительного анализа\n",
    "print(\"\\n=== Дополнительный анализ DFG через NetworkX ===\")\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "# Создаем граф NetworkX из DFG\n",
    "G_dfg = nx.DiGraph()\n",
    "\n",
    "# Добавляем узлы (события)\n",
    "all_events = set()\n",
    "for (source, target), count in dfg.items():\n",
    "    all_events.add(source)\n",
    "    all_events.add(target)\n",
    "\n",
    "for event in all_events:\n",
    "    G_dfg.add_node(event)\n",
    "\n",
    "# Добавляем ребра с весами (частотами)\n",
    "for (source, target), count in dfg.items():\n",
    "    G_dfg.add_edge(source, target, weight=count)\n",
    "\n",
    "print(f\"Граф DFG в NetworkX:\")\n",
    "print(f\"  - Узлов (событий): {G_dfg.number_of_nodes()}\")\n",
    "print(f\"  - Ребер (последовательностей): {G_dfg.number_of_edges()}\")\n",
    "\n",
    "# Анализ центральности\n",
    "print(\"\\nАнализ центральности событий в DFG:\")\n",
    "\n",
    "# Степень центральности (degree centrality)\n",
    "degree_centrality = nx.degree_centrality(G_dfg)\n",
    "sorted_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"События с наибольшей степенью центральности:\")\n",
    "for event, centrality in sorted_degree[:5]:\n",
    "    print(f\"  {event:40}: центральность = {centrality:.3f}\")\n",
    "\n",
    "# Посредническая центральность (betweenness centrality)\n",
    "betweenness_centrality = nx.betweenness_centrality(G_dfg)\n",
    "sorted_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nСобытия с наибольшей посреднической центральностью:\")\n",
    "for event, centrality in sorted_betweenness[:5]:\n",
    "    print(f\"  {event:40}: центральность = {centrality:.3f}\")"
   ],
   "id": "3cfe9671e73f1724",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
